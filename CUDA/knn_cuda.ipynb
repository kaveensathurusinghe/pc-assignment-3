{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd8acf15",
   "metadata": {},
   "source": [
    "## 1. Setup and GPU Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c822e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability and specifications\n",
    "!nvidia-smi\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "!nvidia-smi --query-gpu=name,compute_cap,memory.total --format=csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eab3bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CUDA compiler version\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72afadd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "from google.colab import files\n",
    "import seaborn as sns\n",
    "from IPython.display import Image, display\n",
    "import subprocess\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b85ff9",
   "metadata": {},
   "source": [
    "## 2. Upload Dataset Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf536287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload iris_train.csv and iris_test.csv\n",
    "print(\"Please upload iris_train.csv and iris_test.csv\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Verify files\n",
    "print(\"\\nUploaded files:\")\n",
    "!ls -lh *.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2059a7dd",
   "metadata": {},
   "source": [
    "## 3. Create Configurable CUDA Source Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5cfb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile knn_cuda_configurable.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "#include <string.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#define CUDA_CHECK(call) \\\n",
    "    do { \\\n",
    "        cudaError_t error = call; \\\n",
    "        if (error != cudaSuccess) { \\\n",
    "            fprintf(stderr, \"CUDA error at %s:%d: %s\\n\", __FILE__, __LINE__, \\\n",
    "                    cudaGetErrorString(error)); \\\n",
    "            exit(EXIT_FAILURE); \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "typedef struct {\n",
    "    double *features;\n",
    "    int label;\n",
    "    int id;\n",
    "} DataPoint;\n",
    "\n",
    "typedef struct {\n",
    "    double distance;\n",
    "    int label;\n",
    "} DistanceLabel;\n",
    "\n",
    "typedef struct {\n",
    "    DataPoint *points;\n",
    "    int num_points;\n",
    "    int num_features;\n",
    "} Dataset;\n",
    "\n",
    "int BLOCK_SIZE_X = 16;\n",
    "int BLOCK_SIZE_Y = 16;\n",
    "\n",
    "Dataset* load_csv(const char *filename);\n",
    "void free_dataset(Dataset *dataset);\n",
    "int find_max_label(Dataset *dataset);\n",
    "int compare_distance(const void *a, const void *b);\n",
    "\n",
    "__global__ void calculate_distances_batch_kernel(\n",
    "    double *train_features,\n",
    "    double *test_features,\n",
    "    double *distances,\n",
    "    int num_train,\n",
    "    int num_test,\n",
    "    int num_features\n",
    ") {\n",
    "    int test_idx = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int train_idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    if (test_idx < num_test && train_idx < num_train) {\n",
    "        double sum = 0.0;\n",
    "        for (int f = 0; f < num_features; f++) {\n",
    "            double diff = train_features[train_idx * num_features + f] - \n",
    "                         test_features[test_idx * num_features + f];\n",
    "            sum += diff * diff;\n",
    "        }\n",
    "        distances[test_idx * num_train + train_idx] = sqrt(sum);\n",
    "    }\n",
    "}\n",
    "\n",
    "void knn_predict_batch_gpu(\n",
    "    double *d_train_features,\n",
    "    int *d_train_labels,\n",
    "    double *h_test_features,\n",
    "    int *h_predictions,\n",
    "    int num_train,\n",
    "    int num_test,\n",
    "    int num_features,\n",
    "    int k,\n",
    "    int num_classes\n",
    ") {\n",
    "    double *d_test_features, *d_distances;\n",
    "    CUDA_CHECK(cudaMalloc(&d_test_features, num_test * num_features * sizeof(double)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_distances, num_test * num_train * sizeof(double)));\n",
    "    \n",
    "    CUDA_CHECK(cudaMemcpy(d_test_features, h_test_features, \n",
    "                         num_test * num_features * sizeof(double), \n",
    "                         cudaMemcpyHostToDevice));\n",
    "    \n",
    "    dim3 threads_per_block(BLOCK_SIZE_X, BLOCK_SIZE_Y);\n",
    "    dim3 num_blocks((num_train + BLOCK_SIZE_X - 1) / BLOCK_SIZE_X, \n",
    "                    (num_test + BLOCK_SIZE_Y - 1) / BLOCK_SIZE_Y);\n",
    "    \n",
    "    printf(\"CUDA Configuration: Block size (%d, %d), Grid size (%d, %d)\\n\",\n",
    "           BLOCK_SIZE_X, BLOCK_SIZE_Y, num_blocks.x, num_blocks.y);\n",
    "    \n",
    "    calculate_distances_batch_kernel<<<num_blocks, threads_per_block>>>(\n",
    "        d_train_features, d_test_features, d_distances, \n",
    "        num_train, num_test, num_features\n",
    "    );\n",
    "    CUDA_CHECK(cudaGetLastError());\n",
    "    CUDA_CHECK(cudaDeviceSynchronize());\n",
    "    \n",
    "    double *h_distances = (double*)malloc(num_test * num_train * sizeof(double));\n",
    "    CUDA_CHECK(cudaMemcpy(h_distances, d_distances, \n",
    "                         num_test * num_train * sizeof(double), \n",
    "                         cudaMemcpyDeviceToHost));\n",
    "    \n",
    "    int *h_labels = (int*)malloc(num_train * sizeof(int));\n",
    "    CUDA_CHECK(cudaMemcpy(h_labels, d_train_labels, \n",
    "                         num_train * sizeof(int), cudaMemcpyDeviceToHost));\n",
    "    \n",
    "    for (int t = 0; t < num_test; t++) {\n",
    "        DistanceLabel *dist_labels = (DistanceLabel*)malloc(num_train * sizeof(DistanceLabel));\n",
    "        for (int i = 0; i < num_train; i++) {\n",
    "            dist_labels[i].distance = h_distances[t * num_train + i];\n",
    "            dist_labels[i].label = h_labels[i];\n",
    "        }\n",
    "        \n",
    "        qsort(dist_labels, num_train, sizeof(DistanceLabel), compare_distance);\n",
    "        \n",
    "        int *votes = (int*)calloc(num_classes, sizeof(int));\n",
    "        for (int i = 0; i < k; i++) {\n",
    "            int label = dist_labels[i].label;\n",
    "            if (label >= 0 && label < num_classes) {\n",
    "                votes[label]++;\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        int max_votes = -1;\n",
    "        int predicted_label = -1;\n",
    "        for (int i = 0; i < num_classes; i++) {\n",
    "            if (votes[i] > max_votes) {\n",
    "                max_votes = votes[i];\n",
    "                predicted_label = i;\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        h_predictions[t] = predicted_label;\n",
    "        \n",
    "        free(dist_labels);\n",
    "        free(votes);\n",
    "    }\n",
    "    \n",
    "    free(h_distances);\n",
    "    free(h_labels);\n",
    "    CUDA_CHECK(cudaFree(d_test_features));\n",
    "    CUDA_CHECK(cudaFree(d_distances));\n",
    "}\n",
    "\n",
    "int compare_distance(const void *a, const void *b) {\n",
    "    DistanceLabel *dl_a = (DistanceLabel*)a;\n",
    "    DistanceLabel *dl_b = (DistanceLabel*)b;\n",
    "    if (dl_a->distance < dl_b->distance) return -1;\n",
    "    if (dl_a->distance > dl_b->distance) return 1;\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]) {\n",
    "    char *train_file = \"iris_train.csv\";\n",
    "    char *test_file = \"iris_test.csv\";\n",
    "    int k = 3;\n",
    "    \n",
    "    if (argc >= 4) {\n",
    "        train_file = argv[1];\n",
    "        test_file = argv[2];\n",
    "        k = atoi(argv[3]);\n",
    "    }\n",
    "    \n",
    "    if (argc >= 6) {\n",
    "        BLOCK_SIZE_X = atoi(argv[4]);\n",
    "        BLOCK_SIZE_Y = atoi(argv[5]);\n",
    "    }\n",
    "    \n",
    "    int device_count = 0;\n",
    "    CUDA_CHECK(cudaGetDeviceCount(&device_count));\n",
    "    if (device_count == 0) {\n",
    "        fprintf(stderr, \"No CUDA devices found!\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "    \n",
    "    cudaDeviceProp device_prop;\n",
    "    CUDA_CHECK(cudaGetDeviceProperties(&device_prop, 0));\n",
    "    printf(\"GPU: %s (Compute %d.%d)\\n\", device_prop.name, device_prop.major, device_prop.minor);\n",
    "    \n",
    "    Dataset *train_data = load_csv(train_file);\n",
    "    if (!train_data) return 1;\n",
    "    \n",
    "    Dataset *test_data = load_csv(test_file);\n",
    "    if (!test_data) {\n",
    "        free_dataset(train_data);\n",
    "        return 1;\n",
    "    }\n",
    "    \n",
    "    int max_train_label = find_max_label(train_data);\n",
    "    int max_test_label = find_max_label(test_data);\n",
    "    int num_classes = (max_train_label > max_test_label ? max_train_label : max_test_label) + 1;\n",
    "    \n",
    "    if (train_data->num_features != test_data->num_features) {\n",
    "        fprintf(stderr, \"Error: Feature dimension mismatch!\\n\");\n",
    "        free_dataset(train_data);\n",
    "        free_dataset(test_data);\n",
    "        return 1;\n",
    "    }\n",
    "    \n",
    "    int num_train = train_data->num_points;\n",
    "    int num_test = test_data->num_points;\n",
    "    int num_features = train_data->num_features;\n",
    "    \n",
    "    printf(\"Dataset: %d train, %d test, %d features, %d classes\\n\",\n",
    "           num_train, num_test, num_features, num_classes);\n",
    "    \n",
    "    double *h_train_features = (double*)malloc(num_train * num_features * sizeof(double));\n",
    "    int *h_train_labels = (int*)malloc(num_train * sizeof(int));\n",
    "    double *h_test_features = (double*)malloc(num_test * num_features * sizeof(double));\n",
    "    int *h_test_labels = (int*)malloc(num_test * sizeof(int));\n",
    "    \n",
    "    for (int i = 0; i < num_train; i++) {\n",
    "        for (int j = 0; j < num_features; j++) {\n",
    "            h_train_features[i * num_features + j] = train_data->points[i].features[j];\n",
    "        }\n",
    "        h_train_labels[i] = train_data->points[i].label;\n",
    "    }\n",
    "    \n",
    "    for (int i = 0; i < num_test; i++) {\n",
    "        for (int j = 0; j < num_features; j++) {\n",
    "            h_test_features[i * num_features + j] = test_data->points[i].features[j];\n",
    "        }\n",
    "        h_test_labels[i] = test_data->points[i].label;\n",
    "    }\n",
    "    \n",
    "    double *d_train_features;\n",
    "    int *d_train_labels;\n",
    "    CUDA_CHECK(cudaMalloc(&d_train_features, num_train * num_features * sizeof(double)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_train_labels, num_train * sizeof(int)));\n",
    "    \n",
    "    CUDA_CHECK(cudaMemcpy(d_train_features, h_train_features, \n",
    "                         num_train * num_features * sizeof(double), \n",
    "                         cudaMemcpyHostToDevice));\n",
    "    CUDA_CHECK(cudaMemcpy(d_train_labels, h_train_labels, \n",
    "                         num_train * sizeof(int), \n",
    "                         cudaMemcpyHostToDevice));\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    CUDA_CHECK(cudaEventCreate(&start));\n",
    "    CUDA_CHECK(cudaEventCreate(&stop));\n",
    "    \n",
    "    CUDA_CHECK(cudaEventRecord(start));\n",
    "    \n",
    "    int *h_predictions = (int*)malloc(num_test * sizeof(int));\n",
    "    knn_predict_batch_gpu(d_train_features, d_train_labels, h_test_features, \n",
    "                         h_predictions, num_train, num_test, num_features, \n",
    "                         k, num_classes);\n",
    "    \n",
    "    CUDA_CHECK(cudaEventRecord(stop));\n",
    "    CUDA_CHECK(cudaEventSynchronize(stop));\n",
    "    \n",
    "    float execution_time = 0;\n",
    "    CUDA_CHECK(cudaEventElapsedTime(&execution_time, start, stop));\n",
    "    \n",
    "    int correct_predictions = 0;\n",
    "    for (int i = 0; i < num_test; i++) {\n",
    "        if (h_predictions[i] == h_test_labels[i]) {\n",
    "            correct_predictions++;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    double accuracy = (double)correct_predictions / num_test * 100.0;\n",
    "    \n",
    "    printf(\"\\nRESULTS: Accuracy=%.2f%%, Time=%.4f ms, k=%d\\n\",\n",
    "           accuracy, execution_time, k);\n",
    "    \n",
    "    free(h_train_features);\n",
    "    free(h_train_labels);\n",
    "    free(h_test_features);\n",
    "    free(h_test_labels);\n",
    "    free(h_predictions);\n",
    "    CUDA_CHECK(cudaFree(d_train_features));\n",
    "    CUDA_CHECK(cudaFree(d_train_labels));\n",
    "    CUDA_CHECK(cudaEventDestroy(start));\n",
    "    CUDA_CHECK(cudaEventDestroy(stop));\n",
    "    free_dataset(train_data);\n",
    "    free_dataset(test_data);\n",
    "    \n",
    "    return 0;\n",
    "}\n",
    "\n",
    "Dataset* load_csv(const char *filename) {\n",
    "    FILE *file = fopen(filename, \"r\");\n",
    "    if (!file) return NULL;\n",
    "    \n",
    "    int num_lines = 0;\n",
    "    char buffer[1024];\n",
    "    while (fgets(buffer, sizeof(buffer), file)) num_lines++;\n",
    "    rewind(file);\n",
    "    \n",
    "    if (num_lines == 0) {\n",
    "        fclose(file);\n",
    "        return NULL;\n",
    "    }\n",
    "    \n",
    "    Dataset *dataset = (Dataset*)malloc(sizeof(Dataset));\n",
    "    if (!dataset) {\n",
    "        fclose(file);\n",
    "        return NULL;\n",
    "    }\n",
    "    \n",
    "    dataset->points = (DataPoint*)malloc(num_lines * sizeof(DataPoint));\n",
    "    dataset->num_points = 0;\n",
    "    dataset->num_features = 0;\n",
    "    \n",
    "    while (fgets(buffer, sizeof(buffer), file)) {\n",
    "        buffer[strcspn(buffer, \"\\n\")] = 0;\n",
    "        if (strlen(buffer) == 0) continue;\n",
    "        \n",
    "        int features_in_line = 1;\n",
    "        for (int i = 0; buffer[i] != '\\0'; i++) {\n",
    "            if (buffer[i] == ',') features_in_line++;\n",
    "        }\n",
    "        \n",
    "        if (dataset->num_features == 0) {\n",
    "            dataset->num_features = features_in_line - 1;\n",
    "        }\n",
    "        \n",
    "        if (features_in_line != dataset->num_features + 1) continue;\n",
    "        \n",
    "        dataset->points[dataset->num_points].features = \n",
    "            (double*)malloc(dataset->num_features * sizeof(double));\n",
    "        \n",
    "        char *token = strtok(buffer, \",\");\n",
    "        int feature_idx = 0;\n",
    "        \n",
    "        while (token != NULL && feature_idx < dataset->num_features) {\n",
    "            dataset->points[dataset->num_points].features[feature_idx] = atof(token);\n",
    "            token = strtok(NULL, \",\");\n",
    "            feature_idx++;\n",
    "        }\n",
    "        \n",
    "        if (token != NULL) {\n",
    "            dataset->points[dataset->num_points].label = atoi(token);\n",
    "        }\n",
    "        \n",
    "        dataset->points[dataset->num_points].id = dataset->num_points;\n",
    "        dataset->num_points++;\n",
    "    }\n",
    "    \n",
    "    fclose(file);\n",
    "    return dataset;\n",
    "}\n",
    "\n",
    "int find_max_label(Dataset *dataset) {\n",
    "    if (!dataset || dataset->num_points == 0) return -1;\n",
    "    int max_label = dataset->points[0].label;\n",
    "    for (int i = 1; i < dataset->num_points; i++) {\n",
    "        if (dataset->points[i].label > max_label) {\n",
    "            max_label = dataset->points[i].label;\n",
    "        }\n",
    "    }\n",
    "    return max_label;\n",
    "}\n",
    "\n",
    "void free_dataset(Dataset *dataset) {\n",
    "    if (dataset) {\n",
    "        if (dataset->points) {\n",
    "            for (int i = 0; i < dataset->num_points; i++) {\n",
    "                if (dataset->points[i].features) {\n",
    "                    free(dataset->points[i].features);\n",
    "                }\n",
    "            }\n",
    "            free(dataset->points);\n",
    "        }\n",
    "        free(dataset);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8385084e",
   "metadata": {},
   "source": [
    "## 4. Compile CUDA Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd309003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile with appropriate architecture for Colab GPUs\n",
    "!nvcc -O3 -arch=sm_75 -o knn_cuda knn_cuda_configurable.cu -lm\n",
    "\n",
    "import os\n",
    "if os.path.exists('knn_cuda'):\n",
    "    print(\"\\nâœ“ Compilation successful!\")\n",
    "else:\n",
    "    print(\"\\nâœ— Compilation failed!\")\n",
    "    print(\"\\nTrying alternative architecture...\")\n",
    "    !nvcc -O3 -arch=sm_37 -o knn_cuda knn_cuda_configurable.cu -lm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ef7156",
   "metadata": {},
   "source": [
    "## 5. Performance Analysis - Varying Block Sizes and Thread Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd3fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different block size configurations to test\n",
    "block_configurations = [\n",
    "    (4, 4),\n",
    "    (8, 8),\n",
    "    (16, 16),\n",
    "    (32, 32),\n",
    "    (8, 16),\n",
    "    (16, 8),\n",
    "    (32, 16),\n",
    "    (16, 32),\n",
    "    (64, 4),\n",
    "    (4, 64),\n",
    "    (128, 2),\n",
    "    (2, 128)\n",
    "]\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "baseline_time = None\n",
    "\n",
    "print(\"Running performance tests with different CUDA configurations...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for block_x, block_y in block_configurations:\n",
    "    threads_per_block = block_x * block_y\n",
    "    \n",
    "    # Run the CUDA program with specific block configuration\n",
    "    cmd = f\"./knn_cuda iris_train.csv iris_test.csv 3 {block_x} {block_y}\"\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    output = result.stdout\n",
    "    \n",
    "    # Extract execution time and accuracy\n",
    "    time_match = re.search(r'Time=([0-9.]+)\\s*ms', output)\n",
    "    acc_match = re.search(r'Accuracy=([0-9.]+)%', output)\n",
    "    \n",
    "    if time_match and acc_match:\n",
    "        exec_time = float(time_match.group(1))\n",
    "        accuracy = float(acc_match.group(1))\n",
    "        \n",
    "        # Calculate speedup (using first configuration as baseline)\n",
    "        if baseline_time is None:\n",
    "            baseline_time = exec_time\n",
    "        speedup = baseline_time / exec_time\n",
    "        \n",
    "        results.append({\n",
    "            'Block_X': block_x,\n",
    "            'Block_Y': block_y,\n",
    "            'Threads_Per_Block': threads_per_block,\n",
    "            'Config': f\"{block_x}x{block_y}\",\n",
    "            'Execution_Time_ms': exec_time,\n",
    "            'Accuracy': accuracy,\n",
    "            'Speedup': speedup\n",
    "        })\n",
    "        \n",
    "        print(f\"Config: {block_x:3d}x{block_y:<3d} ({threads_per_block:4d} threads) | \"\n",
    "              f\"Time: {exec_time:7.4f} ms | Accuracy: {accuracy:6.2f}% | Speedup: {speedup:.3f}x\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nCompleted {len(results)} configurations\")\n",
    "\n",
    "# Create DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5285bede",
   "metadata": {},
   "source": [
    "## 6. Generate Performance Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcb6d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph 1: Configuration Parameters vs Execution Time\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "x_labels = df_results['Config']\n",
    "x_pos = np.arange(len(x_labels))\n",
    "exec_times = df_results['Execution_Time_ms']\n",
    "\n",
    "bars = ax.bar(x_pos, exec_times, color=sns.color_palette(\"viridis\", len(x_labels)))\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, time, threads) in enumerate(zip(bars, exec_times, df_results['Threads_Per_Block'])):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{time:.3f}ms\\n({threads}t)',\n",
    "            ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Block Configuration (X x Y)', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Execution Time (ms)', fontsize=13, fontweight='bold')\n",
    "ax.set_title('CUDA Performance: Block Configuration vs Execution Time', \n",
    "             fontsize=15, fontweight='bold', pad=20)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(x_labels, rotation=45, ha='right')\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cuda_config_vs_time.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Graph saved as 'cuda_config_vs_time.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93324cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph 2: Configuration Parameters vs Speedup\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "speedups = df_results['Speedup']\n",
    "bars = ax.bar(x_pos, speedups, color=sns.color_palette(\"rocket\", len(x_labels)))\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, speedup, threads) in enumerate(zip(bars, speedups, df_results['Threads_Per_Block'])):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{speedup:.3f}x\\n({threads}t)',\n",
    "            ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Add baseline reference line\n",
    "ax.axhline(y=1.0, color='red', linestyle='--', linewidth=2, label='Baseline (1.0x)')\n",
    "\n",
    "ax.set_xlabel('Block Configuration (X x Y)', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Speedup (relative to first config)', fontsize=13, fontweight='bold')\n",
    "ax.set_title('CUDA Performance: Block Configuration vs Speedup', \n",
    "             fontsize=15, fontweight='bold', pad=20)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(x_labels, rotation=45, ha='right')\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.legend(fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cuda_config_vs_speedup.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Graph saved as 'cuda_config_vs_speedup.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677f4678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph 3: Threads Per Block vs Execution Time\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Sort by threads per block\n",
    "df_sorted = df_results.sort_values('Threads_Per_Block')\n",
    "\n",
    "# Plot 1: Execution Time\n",
    "ax1.plot(df_sorted['Threads_Per_Block'], df_sorted['Execution_Time_ms'], \n",
    "         marker='o', linewidth=2, markersize=8, color='#2E86AB')\n",
    "ax1.set_xlabel('Threads Per Block', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Execution Time (ms)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Threads Per Block vs Execution Time', fontsize=13, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xscale('log', base=2)\n",
    "\n",
    "# Plot 2: Speedup\n",
    "ax2.plot(df_sorted['Threads_Per_Block'], df_sorted['Speedup'], \n",
    "         marker='s', linewidth=2, markersize=8, color='#A23B72')\n",
    "ax2.axhline(y=1.0, color='red', linestyle='--', linewidth=1, alpha=0.5)\n",
    "ax2.set_xlabel('Threads Per Block', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Speedup', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Threads Per Block vs Speedup', fontsize=13, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_xscale('log', base=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cuda_threads_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Graph saved as 'cuda_threads_analysis.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2acf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph 4: Heatmap of Execution Time by Block Dimensions\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Create pivot tables\n",
    "pivot_time = df_results.pivot_table(values='Execution_Time_ms', \n",
    "                                     index='Block_Y', columns='Block_X', aggfunc='mean')\n",
    "pivot_speedup = df_results.pivot_table(values='Speedup', \n",
    "                                        index='Block_Y', columns='Block_X', aggfunc='mean')\n",
    "\n",
    "# Heatmap 1: Execution Time\n",
    "sns.heatmap(pivot_time, annot=True, fmt='.3f', cmap='YlOrRd', ax=ax1, \n",
    "            cbar_kws={'label': 'Time (ms)'}, linewidths=0.5)\n",
    "ax1.set_title('Execution Time Heatmap (ms)', fontsize=13, fontweight='bold')\n",
    "ax1.set_xlabel('Block X Dimension', fontsize=11, fontweight='bold')\n",
    "ax1.set_ylabel('Block Y Dimension', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Heatmap 2: Speedup\n",
    "sns.heatmap(pivot_speedup, annot=True, fmt='.3f', cmap='RdYlGn', ax=ax2, \n",
    "            cbar_kws={'label': 'Speedup (x)'}, linewidths=0.5)\n",
    "ax2.set_title('Speedup Heatmap', fontsize=13, fontweight='bold')\n",
    "ax2.set_xlabel('Block X Dimension', fontsize=11, fontweight='bold')\n",
    "ax2.set_ylabel('Block Y Dimension', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cuda_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Graph saved as 'cuda_heatmap.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae410cc",
   "metadata": {},
   "source": [
    "## 7. Capture Execution Screenshots with Different Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd531e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run and display output for key configurations\n",
    "key_configs = [(8, 8), (16, 16), (32, 32), (16, 8), (32, 16)]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DETAILED EXECUTION SCREENSHOTS FOR KEY CONFIGURATIONS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "for block_x, block_y in key_configs:\n",
    "    print(\"\\n\" + \"#\"*70)\n",
    "    print(f\"# Configuration: Block Size ({block_x} x {block_y}) - {block_x*block_y} threads per block\")\n",
    "    print(\"#\"*70)\n",
    "    \n",
    "    cmd = f\"./knn_cuda iris_train.csv iris_test.csv 3 {block_x} {block_y}\"\n",
    "    !{cmd}\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e526691f",
   "metadata": {},
   "source": [
    "## 8. Statistical Analysis and Best Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01c1f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best and worst configurations\n",
    "best_time_idx = df_results['Execution_Time_ms'].idxmin()\n",
    "worst_time_idx = df_results['Execution_Time_ms'].idxmax()\n",
    "best_speedup_idx = df_results['Speedup'].idxmax()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PERFORMANCE ANALYSIS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nâœ“ BEST Configuration (Fastest Execution):\")\n",
    "print(f\"  Block Size: {df_results.loc[best_time_idx, 'Config']}\")\n",
    "print(f\"  Threads Per Block: {df_results.loc[best_time_idx, 'Threads_Per_Block']}\")\n",
    "print(f\"  Execution Time: {df_results.loc[best_time_idx, 'Execution_Time_ms']:.4f} ms\")\n",
    "print(f\"  Speedup: {df_results.loc[best_time_idx, 'Speedup']:.3f}x\")\n",
    "print(f\"  Accuracy: {df_results.loc[best_time_idx, 'Accuracy']:.2f}%\")\n",
    "\n",
    "print(\"\\nâœ— WORST Configuration (Slowest Execution):\")\n",
    "print(f\"  Block Size: {df_results.loc[worst_time_idx, 'Config']}\")\n",
    "print(f\"  Threads Per Block: {df_results.loc[worst_time_idx, 'Threads_Per_Block']}\")\n",
    "print(f\"  Execution Time: {df_results.loc[worst_time_idx, 'Execution_Time_ms']:.4f} ms\")\n",
    "print(f\"  Speedup: {df_results.loc[worst_time_idx, 'Speedup']:.3f}x\")\n",
    "print(f\"  Accuracy: {df_results.loc[worst_time_idx, 'Accuracy']:.2f}%\")\n",
    "\n",
    "print(\"\\nðŸ“Š STATISTICS:\")\n",
    "print(f\"  Average Execution Time: {df_results['Execution_Time_ms'].mean():.4f} ms\")\n",
    "print(f\"  Std Deviation (Time): {df_results['Execution_Time_ms'].std():.4f} ms\")\n",
    "print(f\"  Min Time: {df_results['Execution_Time_ms'].min():.4f} ms\")\n",
    "print(f\"  Max Time: {df_results['Execution_Time_ms'].max():.4f} ms\")\n",
    "print(f\"  Time Range: {df_results['Execution_Time_ms'].max() - df_results['Execution_Time_ms'].min():.4f} ms\")\n",
    "\n",
    "improvement = ((df_results.loc[worst_time_idx, 'Execution_Time_ms'] - \n",
    "                df_results.loc[best_time_idx, 'Execution_Time_ms']) / \n",
    "               df_results.loc[worst_time_idx, 'Execution_Time_ms']) * 100\n",
    "\n",
    "print(f\"\\nâš¡ Performance Improvement: {improvement:.2f}%\")\n",
    "print(f\"   (Best config is {improvement:.2f}% faster than worst config)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7566f46d",
   "metadata": {},
   "source": [
    "## 9. Export Results and Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57ab4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "df_results.to_csv('cuda_performance_results.csv', index=False)\n",
    "print(\"âœ“ Results saved to 'cuda_performance_results.csv'\")\n",
    "\n",
    "# Create detailed report\n",
    "with open('cuda_performance_report.txt', 'w') as f:\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"CUDA KNN PERFORMANCE ANALYSIS REPORT\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(f\"GPU Information:\\n\")\n",
    "    gpu_info = subprocess.run([\"nvidia-smi\", \"--query-gpu=name,compute_cap,memory.total\", \"--format=csv,noheader\"], \n",
    "                             capture_output=True, text=True)\n",
    "    f.write(f\"  {gpu_info.stdout}\\n\")\n",
    "    \n",
    "    f.write(f\"\\nTotal Configurations Tested: {len(df_results)}\\n\")\n",
    "    f.write(f\"\\nBest Configuration:\\n\")\n",
    "    f.write(f\"  Block Size: {df_results.loc[best_time_idx, 'Config']}\\n\")\n",
    "    f.write(f\"  Threads: {df_results.loc[best_time_idx, 'Threads_Per_Block']}\\n\")\n",
    "    f.write(f\"  Time: {df_results.loc[best_time_idx, 'Execution_Time_ms']:.4f} ms\\n\")\n",
    "    f.write(f\"  Speedup: {df_results.loc[best_time_idx, 'Speedup']:.3f}x\\n\")\n",
    "    \n",
    "    f.write(f\"\\nPerformance Improvement: {improvement:.2f}%\\n\")\n",
    "    \n",
    "    f.write(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    f.write(\"DETAILED RESULTS\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "    f.write(df_results.to_string())\n",
    "\n",
    "print(\"âœ“ Report saved to 'cuda_performance_report.txt'\")\n",
    "\n",
    "# List all generated files\n",
    "print(\"\\nGenerated Files:\")\n",
    "print(\"  ðŸ“Š cuda_config_vs_time.png\")\n",
    "print(\"  ðŸ“Š cuda_config_vs_speedup.png\")\n",
    "print(\"  ðŸ“Š cuda_threads_analysis.png\")\n",
    "print(\"  ðŸ“Š cuda_heatmap.png\")\n",
    "print(\"  ðŸ“„ cuda_performance_results.csv\")\n",
    "print(\"  ðŸ“„ cuda_performance_report.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7909672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all results\n",
    "print(\"Downloading all files...\\n\")\n",
    "\n",
    "files_to_download = [\n",
    "    'cuda_config_vs_time.png',\n",
    "    'cuda_config_vs_speedup.png',\n",
    "    'cuda_threads_analysis.png',\n",
    "    'cuda_heatmap.png',\n",
    "    'cuda_performance_results.csv',\n",
    "    'cuda_performance_report.txt'\n",
    "]\n",
    "\n",
    "for file in files_to_download:\n",
    "    if os.path.exists(file):\n",
    "        files.download(file)\n",
    "        print(f\"âœ“ Downloaded: {file}\")\n",
    "\n",
    "print(\"\\nâœ… All files ready for download!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
